{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4장. 머신 러닝의 기본 요소(Fundamental Elements of Machine Learning)\n",
    "★ 참고 링크\n",
    "https://github.com/gilbutITbook/006975/\n",
    "\n",
    "※ 이 장에서 다룰 핵심 내용\n",
    "* 분류와 회귀 이외의 머신 러닝 형태\n",
    "* 머신 러닝 모델의 올바른 평가 과정\n",
    "* 딥러닝을 위한 데이터 전처리\n",
    "* 특성 공학\n",
    "* 과대적합 문제 해결\n",
    "* 머신 러닝 문제를 다루는 일반적인 작업 흐름\n",
    "\n",
    "※ 머신 러닝에서 아주 중요한 문제인 과대적합(Overfitting)도 직접 보았습니다. 이 장에서는 딥러닝 문제에 도전하고 해결하기 위해 새롭게 얻은 직관을 확고한 개념으로 정립하겠습니다. 모델 평가, 데이터 전처리, 특성 공학, 과대적합 문제 같은 이런 모든 개념을 머신 러닝 문제를 해결하기 위한 7단계 작업 흐름으로 자세하게 정리하겠습니다.\n",
    "\n",
    "## 4.1 머신 러닝의 네 가지 분류(Four Categories of Machine Learning)\n",
    "* 이전 예제에서 세 가지 종류의 머신 러닝 문제를 다루었습니다. 이진 분류, 다중 분류, 스칼라 회귀입니다. 이 셋은 모두 지도 학습(supervised learning)의 예입니다. 지도 학습의 목표는 훈련 데이터의 입력과 타깃 사이에 있는 관계를 학습하는 것입니다.\n",
    "* 지도 학습은 빙산의 일각일 뿐입니다. 전체 머신 러닝은 복잡한 하위 분류를 가진 방대한 분야입니다. 일반적으로 머신 러닝 알고리즘은 다음 절에서 소개하는 4개의 커다른 범주 안에 속합니다.\n",
    "\n",
    "### 4.1.1 지도 학습(Supervised Learning)\n",
    "* 지도 학습이 가장 흔한 경우입니다. (종종 사람이 레이블링한) 샘플 데이터가 주어지면 알고 있는 타깃(꼬리표(annotation)라고도 합니다)에 입력 데이터를 매핑하는 방법을 학습합니다. 지금까지 이 책에서 본 4개의 예제는 모두 지도 학습의 고전적인 예입니다.요즘 스포트라이트를 받는 광학 문자 판독, 음성 인식, 이미지 분류, 언어 번역 같은 딥러닝의 거의 모든 애플리케이션이 일반적으로 이 범주에 속합니다.\n",
    "★ 지도 학습은 대부분 분류(Classification)와 회귀(Regression)로 구성되지만 다음과 같은 특이한 변종도 많습니다.\n",
    "* 시퀀스 생성(sequence generation): 사진이 주어지면 이를 설명하는 캡션을 생성합니다. 시퀀스 생성은 이따금(시퀀스에 있는 단어나 토큰(token)을 반복적으로 예측하는 것처럼) 일련의 분류 문제로 재구성할 수 있습니다.\n",
    "* 구문 트리(syntax tree)예측: 문장이 주어지면 분해된 구문 트리를 예측합니다.\n",
    "* 물체 감지(object detection): 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자(bounding box)를 그립니다. 이는 (많은 경계 상자 후보가 주어졌을 때 각 상자의 내용을 분류하는) 분류 문제로 표현되거나, 경계 상자의 좌표를 벡터 회귀로 예측하는 회귀와 분류가 결합된 문제로 표현할 수 있습니다.\n",
    "* 이미지 분할(image segmentaion): 사진이 주어졌을 때 픽셀 단위로 특정 물체에 마스킹(masking)을 합니다.\n",
    "\n",
    "### 4.1.2 비지도 학습(Unsupervised Learning)\n",
    "* 머신 러닝은 어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾습니다. 데이터 시각화, 데이터 압축, 데이터의 노이즈 제거 또는 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용합니다. 비지도 학습(Unsupervised Learning)은 데이터 분석에서 빼놓을 수 없는 요소이며, 종종 지도 학습 문제를 풀기 전에 데이터셋을 잘 이해하기 위해 필수적으로 거치는 단계입니다. 차원 축소(Dimensionality Reduction)와 군집(Clustering)이 비지도 학습에서 잘 알려진 범주입니다.\n",
    "\n",
    "### 4.1.3 자기 지도 학습(Self-Supervised Learning)\n",
    "* 자기 지도 학습(Self-Supervised Learning)은 지도 학습의 특별한 경우이지만 별도의 범주로 할 만큼 충분히 다릅니다. 자기 지도 학습은 지도 학습이지만 사람이 만든 레이블을 사용하지 않습니다. 즉 학습 과정에 사람이 개입하지 않는 지도 학습이라고 생각할 수 있습니다. (학습이 무언가에 지도되어야 하므로) 레이블이 여전히 필요하지만 보통 경험적인 알고리즘을(heuristic algorithm)을 사용해서 입력 데이터로부터 생성합니다.\n",
    "* 예를 들어 오토인코더(AutoEncoder)가 잘 알려진 자기 지도 학습의 예입니다. 여기에서 생성된 타깃은 수정하지 않은 원본 입력입니다. 같은 방식으로 지난 프레임이 주어졌을 때 비디오의 다음 프레임을 예측하는 것이나, 이전 단어가 주어졌을 때 다음 단어를 예측하는 것이 자기 지도 학습의 예입니다(이 경우에는 미래의 입력 데이터로부터 지도되기 때문에 시간에 따른 지도 학습(temporally supervised learning)입니다). 지도 학습(Supervised Learning), 자기 지도 학습(Self-Supervised Learning), 비지도 학습(Unsupervised Learning)의 구분은 가끔 모호할 수 있습니다. 이 범주들은 명확한 경계가 없고 연속적입니다. 자기 지도 학습은 학습 메커니즘과 애플리케이션 측면 중 어디에 중점을 두는지에 따라 지도 학습 또는 비지도 학습으로 재해석 될 수 있습니다.\n",
    "\n",
    "★ Note: 지도 학습이 광범위한 산업계의 애플리케이션에 적용되어 오늘날 딥러닝의 대부분을 차지하고 있기 때문에 이 책에서는 특히 지도 학습에 집중하겠습니다. 책의 후반부에서 자기 지도 학습에 대해 잠깐 살펴봅시다.\n",
    "\n",
    "### 4.1.4 강화 학습(Reinforcement Learning)\n",
    "* 오랫동안 간과되었던 강화 학습(Reinforcement Learning)은 구글 딥마인드(DeepMind)가 아타리(Atari) 게임 플레이를 학습하는 데 성공적으로 적용하면서 최근에 많은 관심을 받기 시작했습니다(그 이후 최고 수준의 바둑 실력을 학습했습니다). 강화 학습에서 에이전트(agent)는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습됩니다. 예를 들어 강화 학습으로 훈련된 신경망은 비디오 게임 화면을 입력으로 받고 게임 점수를 최대화하기 위한 게임 내의 행동을 출력할 수 있습니다.\n",
    "* 현재 강화 학습은 대부분 연구 영역에 속해 있고 게임 이외에 실제적인 성공 사례는 아직 없습니다.하지만 때가 되면 강화 학습이 실제 세상의 많은 애플리케이션을 대체할 것으로 기대하고 있습니다. 이런 애플리케이션에는 자율 주행 자동차, 자원 관리, 교육 등이 있습니다. 아마 그때가 왔거나 이제 곧 올 것입니다.\n",
    "\n",
    "★ Note <분류(Classification)와 회귀(Regression)에서 사용하는 용어>\n",
    "\n",
    "분류와 회귀에는 특별한 용어가 많습니다. 이전 예제에서 일부 용어를 보았고 앞으로 이어지는 장들에서 더 많이 등장합니다. 이런 용어들은 머신 러닝에 특화된 구체적인 정의를 가지므로 친숙해져야 합니다.\n",
    "* 샘플 또는 입력: 모델에 주입될 하나의 데이터 포인트\n",
    "* 예측 또는 출력: 모델로부터 나오는 값\n",
    "* 타깃: 정답. 외부 데이터 소스에 근거하여 모델이 완벽하게 예측해야 하는 값\n",
    "* 예측 오차 또는 손실 값:모델의 예측과 타깃 사이의 거리를 측정한 값\n",
    "* 클래스: 분류 문제에서 선택할 수 있는 가능한 레이블의 집합. 예를 들어 고양이와 강아지 사진을 분류할 때 클래스는 '고양이'와 '강아지' 2개입니다.\n",
    "* 레이블: 분류 문제에서 클래스 할당의 구체적인 사례. 예를 들어 사진 #1234에 '강아지' 클래스가 들어 있다고 표시한다면 '강아지'는 사진 #1234의 레이블이 됩니다.\n",
    "* 참 값(ground-truth) 또는 꼬리표(annotation): 데이터셋에 대한 모든 타깃. 일반적으로 사람에 의해 수집됩니다.\n",
    "* 이진 분류: 각 입력 샘플이 2개의 배타적인 범주로 구분되는 분류 작업\n",
    "* 다중 분류: 각 입력 샘플이 2개 이상의 범주로 구분되는 분류 작업. 예를 들어 손글씨 숫자 분류를 말합니다.\n",
    "* 다중 레이블 분류: 각 입력 샘플이 여러 개의 레이블에 할당될 수 있는 분류 작업. 예를 들어 하나의 이미지에 고양이와 강아지가 모두 들어 있을 때는 '고양이' 레이블과 '강아지' 레이블을 모두 할당해야 합니다. 보통 이미지마다 레이블의 개수는 다릅니다.\n",
    "* 스칼라 회귀: 타깃이 연속적인 스칼라 값인 작업. 주택 가격 예측이 좋은 예입니다. 각기 다른 타깃 가격이 연속적인 공간을 형성합니다.\n",
    "* 벡터 회귀: 타깃이 연속적인 값의 집합인 작업. 예를 들어 연속적인 값으로 이루어진 벡터입니다. (이미지에 있는 경계 상자의 좌표 같은) 여러 개의 값에 대한 회귀를 한다면 벡터 회귀입니다.\n",
    "* 미니 배치 또는 배치: 모델에 의해 동시에 처리되는 소량의 샘플 묶음(일반적으로 8개에서 128개 사이). 샘플 개수는 GPU의 메모리 할당이 용이하도록 2의 거듭제곱으로 하는 경우가 많습니다. 훈련할 때 미니 배치마다 한 번씩 모델의 가중치에 적용할 경사 하강법 업데이트 값을 계산합니다.\n",
    "\n",
    "\n",
    "## 4.2 머신 러닝 모델 평가\n",
    "* 3장에서 본 3개의 예제에서 데이터를 훈련 세트(Training Set), 검증 세트(Validation Set), 테스트 세트(Test Set)로 나누었습니다. 훈련에 사용된 동일한 데이터로 모델을 평가하지 않는 이유는 금방 드러났습니다. 몇 번의 에포크(Epoch) 후에 3개의 모델이 모두 **과대적합(Overfitting)**되기 시작했습니다. 즉 훈련 데이터의 성능에 비해 처음 본 데이터에 대한 성능이 좋아지지 않습니다(또는 더 나빠집니다). 반면에 훈련 데이터의 성능은 훈련이 진행될수록 항상 증가됩니다.\n",
    "* 머신 러닝의 목표는 처음 본 데이터에서 잘 작동하는 일반화된 모델을 얻는 것입니다. 여기에서 과대적합은 주요 장애물입니다. 관측할 수 있는 것만 제어할 수 있으므로 모델의 일반화 성능에 대한 신뢰할 수 있는 측정 방법이 아주 중요합니다. 다음 절에서 과대적합을 완화하고 일반화를 최대화하기 위한 전략을 살펴보겠습니다. 이 절에서는 일반화, 즉 머신 러닝 모델의 성능을 어떻게 측정하는지에 집중합니다.\n",
    "\n",
    "### 4.2.1 훈련, 검증, 테스트 세트\n",
    "* 모델 평가의 핵심은 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나누는 것입니다. 훈련 세트에서 모델을 훈련하고 검증 세트에서 모델을 평가합니다. 모델을 출시할 준비가 되면 테스트 세트에서 최종적으로 딱 한 번 모델을 테스트합니다.\n",
    "* 훈련 세트와 테스트 세트 2개를 사용하면 어떨까요? 훈련 세트에서 훈련하고 테스트 세트에서 평가하는 것이죠.\n",
    "* 이렇게 하지 않는 이유는 모델을 개발할 때 항상 모델의 설정을 튜닝하기 때문입니다. 예를 들어 층의 수난 층의 유닛 수를 선택합니다(이런 파라미터를 네트워크의 가중치와 구분하기 위해 하이퍼파라미터(hyperparameter)라고 부릅니다). 검증 세트에서 모델의 성능을 평가하여 이런 튜닝을 수행합니다. 본질적으로 이런 튜닝도 어떤 파라미터 공간에서 좋은 설정을 찾는 학습입니다. 결국 검증 세트의 성능을 기반으로 모델의 설정을 튜닝하면 검증 세트로 모델을 직접 훈련하지 않더라도 빠르게 검증 세트에 과대적합될 수 있습니다.\n",
    "* 이 현상의 핵심은 정보 누설(information leak) 개념에 있습니다. 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것입니다. 하나의 파라미터에 대해서 단 한 번만 튜닝한다면 아주 적은 정보가 누설됩니다. 이런 검증 세트로는 모델을 평가할 만합니다. 하지만 한 번 튜닝하고 나서 검증 세트에 평가한 결과를 가지고 다시 모델을 조정하는 과정을 여러 번 반복하면, 검증 세트에 관한 정보를 모델에 아주 많이 노출시키게 됩니다.\n",
    "* 검증 데이터에 맞추어 최적화했기 때문에 검증 데이터에 의도적으로 잘 수행되는 모델이 만들어집니다. 검증 데이터가 아니고 완전히 새로운 데이터에 대한 성능이 관심 대상이라면 모델을 평가하기 위해 이전에 본 적 없는 완전히 다른 데이터셋을 사용해야 합니다. 바로 테스트 세트입니다. 모델은 간접적으로라도 테스트 세트에 대한 어떤 정보도 얻어서는 안 됩니다. 테스트 세트 성능에 기초하여 튜닝한 모델의 모든 설정은 일반화 성능을 왜곡시킬 것입니다.\n",
    "* 데이터를 훈련, 검증, 테스트 세트로 나누는 것은 간단해 보일 수 있지만 데이터가 적을 때는 몇 가지 고급 기법을 사용하면 도움이 됩니다. 대표적인 세 가지 평가 방법인 단순 홀드아웃 검증(hold-out validation), K-겹 교차 검증(K-fold cross-validation), 셔플링(shuffling)을 사용한 반복 K-겹 교차 검증(iterated K-fold cross-validation)을 살펴보겠습니다.\n",
    "\n",
    "**단순 홀드아웃 검증**\n",
    "* 데이터의 일정량을 테스트 세트로 떼어 놓고, 남은 데이터에서 훈련하고 테스트 세트로 평가합니다. 앞 절에서 설명했듯이 정보 누설을 막기 위해 테스트 세트를 사용해 모델을 튜닝해서는 안 됩니다. 이런 이유로 검증 세트도 따로 떼어 놓아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 홀드아웃 검증 구현 예\n",
    "# 데이터 로드하기\n",
    "num_validation_samples = 10000\n",
    "# 데이터를 섞는 것(셔플링)이 일반적으로 좋습니다.\n",
    "np.random.shuffle(data)\n",
    "# 검증 세트를 만듭니다.\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "# 훈련 세트를 만듭니다.\n",
    "training_data = data[:]\n",
    "\n",
    "# 훈련 세트에서 모델을 훈련하고 검증 세트로 평가합니다.\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# 여기에서 모델을 튜닝하고,\n",
    "# 다시 훈련하고, 평가하고, 또 다시 튜닝하고, 훈련하고, 평가하고...\n",
    "# 하이퍼파라미터 튜닝이 끝나면 테스트 데이터를 제외한 \n",
    "# 모든 데이터를 사용하여 모델을 다시 훈련시킵니다.\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data,\n",
    "                            validation_data]))\n",
    "# 평가 점수\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이 평가 방법은 단순해서 한 가지 단점이 있습니다. 데이터가 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할 수 있습니다. 쉽게 이를 확인할 수 있습니다. 다른 난수 초깃값으로 셔플링해서 데이터를 나누었을 때 모델의 성능이 매우 달라지면 바로 이 문제입니다. 다음에 이야기할 K-겹 교차 검증과 반복 K-겹 교차 검증이 이 문제를 해결할 수 있습니다.\n",
    "\n",
    "**K-겹 교차 검증(K-fold cross-validation)**\n",
    "* 이 방식에서는 데이터를 동일한 크기를 가진 K개 분할로 나눕니다. 각 분할 i에 대해 남은 K - 1개의 분할로 모델을 훈련하고 분할 i에서 분할을 평가합니다. 최종 점수는 이렇게 얻은 K개의 점수를 평균합니다. 이 방법은 모델의 성능이 데이터 분할에 따라 편차가 클 때 도움이 됩니다. 홀드 아웃 검증처럼 이 방법은 모델의 튜닝에 별개의 검증 세트를 사용하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-겹 교차 검증 구현 예\n",
    "# K-겹 교차 검증은 사이킷런(Scikit-learn)의 cross_validate() 함수를 사용하여\n",
    "# 쉽게 구할 수 있습니다. 이 함수를 사용하려면 케라스 모델을 사이킷런과 호환되도록\n",
    "# KerasClassifier나 KerasRegressor 클래스로 모델을 감싸야 합니다.\n",
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "# 데이터를 섞는 것이 일반적으로 좋습니다.\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    # 검증 데이터 부분을 선택합니다.\n",
    "    validation_data = data[num_validation_samples * fold:\n",
    "      num_validation_samples * (fold + 1)]\n",
    "    # 남은 데이터를 훈련 데이터로 사용합니다.\n",
    "    # 리스트에서 '+' 연산자는 두 리스트를 더하는 것이 아니고 연결합니다.\n",
    "    training_data = data[:num_validation_samples * fold] +\n",
    "      data[num_validation_samples * (fold + 1):]\n",
    "    # 훈련되지 않은 새로운 모델을 만듭니다.\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "# 검증 점수: K개 폴드의 검증 점수 평균    \n",
    "validation_score = np.average(validation_scores)\n",
    "# 테스트 데이터를 제외한 전체 데이터로 최종 모델을 훈련합니다.\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**셔플링을 사용한 반복 K-겹 교차 검증(Iterated K-fold cross validation using shuffling)**\n",
    "* 이 방법은 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용합니다. 케글 경연에서는 이 방법이 아주 크게 도움이 됩니다. 이 방법은 K-겹 교차 검증을 여러 번 적용하되 K개의 분할로 나누기 전에 매번 데이터를 무작위로 섞습니다. 최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균이 됩니다. 결국 P X K개(P는 반복 횟수)의 모델을 훈련하고 평가하므로 비용이 매우 많이 듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 데이터 전처리, 특성 공학, 특성 학습\n",
    "\n",
    "### 4.3.1 신경망을 위한 데이터 전처리\n",
    "* 데이터 전처리 목적은 주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것입니다. 벡터화(vectorization), 정규화(normalization), 누락된 값 다루기, 특성 추출 등이 포함됩니다.\n",
    "\n",
    "**벡터화(vectorization)**\n",
    "* 신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서(tensor)여야 합니다(또는 특정 경우에 정수로 이루어진 텐서입니다). 사운드, 이미지, 텍스트 등 처리해야 할 것이 무엇이든지 먼저 텐서로 변환해야 합니다. 이 단계를 데이터 벡터화(data vectorization)라고 합니다.\n",
    "* 예를 들어 이전에 나온 2개의 텍스트 분류 예에서 텍스트를 (단어 시퀀스를 의미하는) 정수 리스트로 변환했습니다. 그다음 원-핫 인코딩을 사용하여 float32 타입의 데이터로 이루어진 텐서로 바꾸었습니다. 숫자 이미지 분류와 주택 가격 예측의 예에서는 이미 데이터가 벡터 형태로 주어졌으므로 이 단계를 건너뛰었습니다.\n",
    "\n",
    "**값 정규화(Normalize values)**\n",
    "\n",
    "* 숫자 이미지 분류 예에서 이미지 데이터를 그레이스케일 인코딩인 `0~255` 사이의 정수로 인코딩했습니다. 이 데이터를 네트워크에 주입하기 전에 float32 타입으로 변경하고 255로 나누어서 최종적으로 `0~1` 사이의 부동 소수 값으로 만들었습니다. 주택 가격을 예측할 때는 특성들의 범위가 제각각이었습니다. 어떤 특성은 작은 부동 소수 값이고 다른 특성은 매우 큰 정수 값을 가졌습니다. 이 데이터를 네트워크에 주입하기 전에 각 특성을 독립적으로 정규화하여 평균이 0이고 표준 편차가 1이 되도록 만들었습니다.\n",
    "* 일반적으로 비교적 큰 값(예를 들어 네트워크의 가중치 초깃값보다 훨씬 큰 여러 자릿수를 가진 정수)이나 균일하지 않은 데이터(예를 들어 한 특성의 범위는 `0~1`이고 다른 특성은 `100~200`인 데이터)를 신경망에 주입하는 것은 위험합니다. 이렇게 하면 업데이트할 그래디언트가 커져 네트워크가 수렴하는 것을 방해합니다. 네트워크를 쉽게 학습시키려면 데이터가 다음 특징을 따라야 합니다.\n",
    "    * 작은 값을 취합니다. 일반적으로 대부분의 값이 0~1 사이여야 합니다.\n",
    "    * 균일해야 합니다. 즉 모든 특성이 대체로 비슷한 범위를 가져야 합니다.\n",
    "\n",
    "* 추가적으로 다음에 나오는 엄격한 정규화 방법은 꼭 필수적이지는 않지만(예를 들어 숫자 이미지 분류 예에서는 사용하지 않았습니다) 자주 사용되고 도움이 될 수 있습니다.\n",
    "    * 각 특성별로 평균이 0이 되도록 정규화합니다.\n",
    "    * 각 특성별로 표준 편차가 1이 되도록 정규화합니다.\n",
    "* 넘파이 배열에서 하는 방법은 간단합니다.\n",
    "    * x -= x.mean(axis=0)\n",
    "    * x /= x.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 과대적합과 과소적합(Overfitting and Underfitting)\n",
    "\n",
    "* 머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기입니다. 최적화(Optimization)는 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정입니다(머신 러닝의 학습). 반면에 일반화(generalization)는 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미합니다. 물론 모델을 만드는 목적은 좋은 일반환 성능을 얻는 것입니다. 하지만 일반화 성능을 제어할 방법이 없습니다. 단지 훈련 데이터를 기반으로 모델을 조정할 수만 있습니다.\n",
    "* 훈련 초기에 최적화와 일반화는 상호 연관되어 있습니다. 훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실도 낮아집니다. 이런 상황이 발생할 때 모델이 과소적합(underfitting) 되었다고 말합니다. 모델의 성능이 계속 발전될 여지가 있습니다. 즉 네트워크가 훈련 데이터에 있는 관련 특성을 모두 학습하지 못했습니다.\n",
    "* 하지만 훈련 데이터에 여러 번 반복 학습하고 나면 어느 시점부터 일반화 성능이 더 이상 높아지지 않습니다. 검증 세트의 성능이 멈추고 감소되기 시작합니다. 즉 모델이 과대적합되기 시작합니다. 이는 훈련 데이터에 특화된 패턴을 학습하기 시작했다는 의미입니다. 이 패턴은 새로운 데이터와 연관성이 적어 잘못된 판단을 하게 만듭니다.\n",
    "\n",
    "### 4.4.1 네트워크 크기 축소\n",
    "* 과대적합(Overfitting)을 막는 가장 단순한 방법은 모델의 크기, 즉 모델에 있는 학습 파라미터의 수를 줄이는 것입니다. 파라미터의 수는 층의 수와 각 층의 유닛 수에 의해 결정됩니다. 딥러닝에서 모델에 있는 학습 파라미터의 수를 종종 모델의 용량(capacity)이라고 말합니다. 당연하게 파라미터가 많은 모델이 기억 용량이 더 많습니다. 훈련 샘플과 타깃 사이를 딕셔너리 같은 일대일 매핑으로 완벽하게 학습할 수도 있습니다. 이런 매핑은 일반화 능력이 없습니다. 예를 들어 50만 개의 이진 파라미터가 있는 모델은 MNIST 훈련 세트의 숫자 이미지 클래스를 모두 쉽게 학습할 수 있습니다.\n",
    "* 5만 개의 숫자 이미지 하나마다 10개의 이진 파라미터만 있으면 됩니다. 하지만 이런 모델은 새로운 숫자 샘플을 분류하는 용도로는 쓸모가 없습니다. 항상 유념해야 할 것은 딥러닝 모델은 훈련 데이터에 잘 맞추려는 경향이 있다는 점입니다. 하지만 진짜 문제는 최적화가 아니고 일반화입니다.\n",
    "* 다른 한편으로 네트워크가 기억 용량에 제한이 있다면 이런 매핑을 쉽게 학습하지 못할 것입니다. 따라서 손실을 최소화하기 위해 타깃에 대한 예측 성능을 가진 압축된 표현을 학습해야 합니다. 정확히 이런 표현이 우리 관심 대상입니다. 동시에 기억해야 할 것은 과소적합되지 않도록 충분한 파라미터를 가진 모델을 사용해야 한다는 점입니다. 모델의 기억 용량이 부족해서는 안 됩니다. 너무 많은 용량과 충분하지 않은 용량 사이의 절충점을 찾아야 합니다.\n",
    "* 안타깝지만 알맞은 층의 수나 각 층의 유닛 수를 결정할 수 있는 마법 같은 공식은 없습니다. 데이터에 알맞은 모델 크기를 찾으려면 각기 다른 구조를 평가해 보아야 합니다. 적절한 모델 크기를 찾는 일반적인 작업 흐름은 비교적 적은 수의 층과 파라미터로 시작합니다. 그다음 검증 손실이 감소되기 시작할 때까지 층이나 유닛의 수를 늘리는 것입니다.\n",
    "\n",
    "※ 3장 5절에 있는 코드를 사용해 데이터를 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wnstj\\anaconda3\\lib\\site-packages\\keras\\datasets\\imdb.py:99: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\wnstj\\anaconda3\\lib\\site-packages\\keras\\datasets\\imdb.py:100: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# 레이블을 벡터로 변환합니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b31f8299dacf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moriginal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0moriginal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0moriginal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# Add to the model any layers passed to the constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_base_init\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[1;34m(prefix)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "# 원본 모델(Original Model)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 더 작은 네트워크로 바꾸어 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "# 작은 용량의 모델(smaller model)\n",
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(6, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 28s 531ms/step - loss: 0.5512 - acc: 0.7395 - val_loss: 0.3477 - val_acc: 0.8742\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.2802 - acc: 0.9093 - val_loss: 0.2901 - val_acc: 0.8880\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 3s 54ms/step - loss: 0.2046 - acc: 0.9300 - val_loss: 0.2823 - val_acc: 0.8881\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1644 - acc: 0.9442 - val_loss: 0.3057 - val_acc: 0.8790\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1365 - acc: 0.9566 - val_loss: 0.3213 - val_acc: 0.8764\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1221 - acc: 0.9599 - val_loss: 0.3341 - val_acc: 0.8758\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.1020 - acc: 0.9671 - val_loss: 0.3610 - val_acc: 0.8709\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0940 - acc: 0.9713 - val_loss: 0.4389 - val_acc: 0.8543\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 3s 56ms/step - loss: 0.0805 - acc: 0.9749 - val_loss: 0.4155 - val_acc: 0.8639\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0695 - acc: 0.9794 - val_loss: 0.4501 - val_acc: 0.8650\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 3s 57ms/step - loss: 0.0592 - acc: 0.9832 - val_loss: 0.4734 - val_acc: 0.8623\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 3s 53ms/step - loss: 0.0487 - acc: 0.9869 - val_loss: 0.4979 - val_acc: 0.8602\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0415 - acc: 0.9892 - val_loss: 0.5285 - val_acc: 0.8589\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0379 - acc: 0.9901 - val_loss: 0.6010 - val_acc: 0.8554\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0333 - acc: 0.9911 - val_loss: 0.6005 - val_acc: 0.8554\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0258 - acc: 0.9937 - val_loss: 0.6494 - val_acc: 0.8516\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0194 - acc: 0.9953 - val_loss: 0.6778 - val_acc: 0.8533\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0153 - acc: 0.9971 - val_loss: 0.7509 - val_acc: 0.8460\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0129 - acc: 0.9975 - val_loss: 0.7617 - val_acc: 0.8510\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0080 - acc: 0.9991 - val_loss: 0.8032 - val_acc: 0.8507\n"
     ]
    }
   ],
   "source": [
    "original_model_hist = original_model.fit(x_train, y_train,\n",
    "                                         epochs=20,\n",
    "                                         batch_size=512,\n",
    "                                         validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 20s 374ms/step - loss: 0.5772 - acc: 0.7533 - val_loss: 0.3941 - val_acc: 0.8729\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 5s 108ms/step - loss: 0.3309 - acc: 0.9003 - val_loss: 0.3197 - val_acc: 0.8830\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.2491 - acc: 0.9187 - val_loss: 0.2864 - val_acc: 0.8907\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.2011 - acc: 0.9330 - val_loss: 0.2787 - val_acc: 0.8898\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1747 - acc: 0.9434 - val_loss: 0.2826 - val_acc: 0.8875\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1508 - acc: 0.9494 - val_loss: 0.2896 - val_acc: 0.8861\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1398 - acc: 0.9544 - val_loss: 0.3028 - val_acc: 0.8830\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1229 - acc: 0.9585 - val_loss: 0.3291 - val_acc: 0.8755\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.1122 - acc: 0.9636 - val_loss: 0.3512 - val_acc: 0.8704\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.1045 - acc: 0.9676 - val_loss: 0.3477 - val_acc: 0.8738\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.0908 - acc: 0.9736 - val_loss: 0.3679 - val_acc: 0.8701\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.0839 - acc: 0.9748 - val_loss: 0.3922 - val_acc: 0.8668\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 3s 54ms/step - loss: 0.0824 - acc: 0.9757 - val_loss: 0.4043 - val_acc: 0.8662\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0739 - acc: 0.9795 - val_loss: 0.4413 - val_acc: 0.8598\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.0673 - acc: 0.9814 - val_loss: 0.4470 - val_acc: 0.8640\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0616 - acc: 0.9843 - val_loss: 0.4675 - val_acc: 0.8605\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0583 - acc: 0.9848 - val_loss: 0.4913 - val_acc: 0.8584\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0510 - acc: 0.9871 - val_loss: 0.5115 - val_acc: 0.8598\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 2s 42ms/step - loss: 0.0455 - acc: 0.9903 - val_loss: 0.5416 - val_acc: 0.8523\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 3s 51ms/step - loss: 0.0427 - acc: 0.9904 - val_loss: 0.5583 - val_acc: 0.8554\n"
     ]
    }
   ],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 21)\n",
    "original_model_val_loss = original_model_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 'b+' 는 파란색 덧셈 기호를 의미합니다.\n",
    "plt.plot(epochs, original_model_val_loss, 'b+', label='Original model')\n",
    "# 'bo' 는 파란색 점을 의미합니다.\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.title('Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[검증 손실에 대한 모델 용량의 효과: 작은 용량의 모델과 비교(Effectiveness of model capacity about validation losses: compared to smaller capacity models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 큰 용량의 모델(Bigger model)\n",
    "\n",
    "bigger_model = models.Sequential()\n",
    "bigger_model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n",
    "bigger_model.add(layers.Dense(1024, activation='relu'))\n",
    "bigger_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "bigger_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 85s 2s/step - loss: 0.8138 - acc: 0.7074 - val_loss: 0.3465 - val_acc: 0.8564\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 79s 2s/step - loss: 0.2403 - acc: 0.8997 - val_loss: 0.2776 - val_acc: 0.8884\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 92s 2s/step - loss: 0.1110 - acc: 0.9620 - val_loss: 0.4189 - val_acc: 0.8333\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 87s 2s/step - loss: 0.0473 - acc: 0.9884 - val_loss: 0.4486 - val_acc: 0.8834\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 79s 2s/step - loss: 0.0204 - acc: 0.9971 - val_loss: 0.4865 - val_acc: 0.8712\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 77s 2s/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6542 - val_acc: 0.8819\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 71s 1s/step - loss: 1.6158e-04 - acc: 1.0000 - val_loss: 0.8372 - val_acc: 0.8794\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 76s 2s/step - loss: 1.3061e-05 - acc: 1.0000 - val_loss: 1.0784 - val_acc: 0.8752\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 87s 2s/step - loss: 0.3744 - acc: 0.9807 - val_loss: 0.7699 - val_acc: 0.8824\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 111s 2s/step - loss: 1.1886e-05 - acc: 1.0000 - val_loss: 0.8245 - val_acc: 0.8828\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 115s 2s/step - loss: 3.6538e-06 - acc: 1.0000 - val_loss: 0.9056 - val_acc: 0.8828\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 75s 2s/step - loss: 1.0998e-06 - acc: 1.0000 - val_loss: 1.0233 - val_acc: 0.8836\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 72s 1s/step - loss: 2.3415e-07 - acc: 1.0000 - val_loss: 1.1561 - val_acc: 0.8844\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 71s 1s/step - loss: 5.6260e-08 - acc: 1.0000 - val_loss: 1.2601 - val_acc: 0.8841\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 71s 1s/step - loss: 1.9445e-08 - acc: 1.0000 - val_loss: 1.3150 - val_acc: 0.8838\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 66s 1s/step - loss: 1.1000e-08 - acc: 1.0000 - val_loss: 1.3458 - val_acc: 0.8839\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 65s 1s/step - loss: 7.3113e-09 - acc: 1.0000 - val_loss: 1.3691 - val_acc: 0.8840\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 61s 1s/step - loss: 5.7377e-09 - acc: 1.0000 - val_loss: 1.3846 - val_acc: 0.8840\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 61s 1s/step - loss: 5.1363e-09 - acc: 1.0000 - val_loss: 1.3986 - val_acc: 0.8839\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 63s 1s/step - loss: 4.1611e-09 - acc: 1.0000 - val_loss: 1.4104 - val_acc: 0.8840\n"
     ]
    }
   ],
   "source": [
    "bigger_model_hist = bigger_model.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigger_model_val_loss = bigger_model_hist.history['val_loss']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# 'b+' 는 파란색 덧셈 기호를 의미합니다.\n",
    "plt.plot(epochs, original_model_val_loss, 'b+', label='Original model')\n",
    "# 'bo' 는 파란색 점을 의미합니다.\n",
    "plt.plot(epochs, bigger_model_val_loss, 'bo', label='Bigger model')\n",
    "plt.title('Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[검증 손실에 대한 모델 용량의 효과: 큰 용량의 모델과 비교(Effectiveness of model capacity about validation losses: compared to bigger capacity models)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2 가중치 규제 추가(add weight regularization)\n",
    "\n",
    "\n",
    "* 오캄의 면도날(Occam's razor) 이론을 알고 있을지 모르겠습니다. 어떤 것에 대한 두 가지의 설명이 있다면 더 적은 가정이 필요한 간다한 설명이 옳을 것이라는 이론입니다. 이 개념은 신경망으로 학습되는 모델에도 적용됩니다. 어떤 훈련 데이터와 네트워크 구조가 주어졌을 때 데이터를 설명할 수 있는 가중치 값의 집합은 여러 개(여러 개의 모델)입니다. 간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높습니다.\n",
    "* 여기에서 간단한 모델은 파라미터 값 분포의 엔트로피가 작은 모델입니다(또는 앞 절에서 본 것처럼 적은 수의 파라미터를 가진 모델입니다). 그러므로 과대적합을 완화하기 위한 일반적인 방법은 네트워크의 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것입니다. 가중치 값의 분포가 더 균일하게 됩니다. 이를 **가중치 규제(weight regularization)**라고 하며, 네트워크의 손실 함수에 큰 가중치에 연관된 비용을 추가합니다. 두 가지 형태의 비용이 있습니다.\n",
    "    * L1 규제: 가중치의 절댓값에 비례하는 비용이 추가됩니다(가중치의 L1 노름(norm)).\n",
    "    * L2 규제: 가중치의 제곱에 비례하는 비용이 추가됩니다(가중치의 L2 노름, 유클리디안 노름(Euclidean norm)이라고도 부릅니다.). L2 규제는 신경망에서 **가중치 감쇠(weight decay)**라고도 부릅니다. 이름이 다르지만 혼동하지 마세요. 가중치 감쇠는 수학적으로 L2 규제와 동일합니다.\n",
    "* 케라스에서 가중치 규제 객체를 층의 키워드 매개변수로 전달하여 가중치 규제를 추가할 수 있습니다. 영화 리뷰 분류 네트워크에 L2 가중치 규제를 추가해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 L2 가중치 추가하기\n",
    "from keras import regularizers\n",
    "\n",
    "l2_model = models.Sequential()\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                       activation='relu', input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                       activation='relu'))\n",
    "l2_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - 22s 394ms/step - loss: 0.5849 - acc: 0.7438 - val_loss: 0.3869 - val_acc: 0.8714\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 5s 95ms/step - loss: 0.3230 - acc: 0.9055 - val_loss: 0.3451 - val_acc: 0.8825\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 3s 62ms/step - loss: 0.2700 - acc: 0.9230 - val_loss: 0.3344 - val_acc: 0.8874\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 3s 55ms/step - loss: 0.2454 - acc: 0.9323 - val_loss: 0.3386 - val_acc: 0.8849\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2267 - acc: 0.9389 - val_loss: 0.3429 - val_acc: 0.8851\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2180 - acc: 0.9436 - val_loss: 0.3989 - val_acc: 0.8651\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.2162 - acc: 0.9434 - val_loss: 0.3648 - val_acc: 0.8777\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 3s 55ms/step - loss: 0.2055 - acc: 0.9478 - val_loss: 0.3735 - val_acc: 0.8765\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 3s 54ms/step - loss: 0.2033 - acc: 0.9496 - val_loss: 0.4072 - val_acc: 0.8652\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.2021 - acc: 0.9481 - val_loss: 0.3863 - val_acc: 0.8729\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 3s 57ms/step - loss: 0.1901 - acc: 0.9543 - val_loss: 0.3966 - val_acc: 0.8708\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 3s 57ms/step - loss: 0.1977 - acc: 0.9495 - val_loss: 0.4138 - val_acc: 0.8674\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 3s 58ms/step - loss: 0.1962 - acc: 0.9493 - val_loss: 0.4008 - val_acc: 0.8714\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 3s 55ms/step - loss: 0.1863 - acc: 0.9547 - val_loss: 0.4050 - val_acc: 0.8702\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1826 - acc: 0.9562 - val_loss: 0.4060 - val_acc: 0.8694\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 3s 53ms/step - loss: 0.1842 - acc: 0.9553 - val_loss: 0.4116 - val_acc: 0.8691\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1749 - acc: 0.9613 - val_loss: 0.4167 - val_acc: 0.8685\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.1837 - acc: 0.9540 - val_loss: 0.4493 - val_acc: 0.8619\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.1687 - acc: 0.9634 - val_loss: 0.4285 - val_acc: 0.8673\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 0.1741 - acc: 0.9588 - val_loss: 0.4245 - val_acc: 0.8684\n"
     ]
    }
   ],
   "source": [
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=20,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_model_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[검증 손실에 대한 L2 가중치 규제의 효과(Effectiveness of L2 weight regularization about validation loss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
