{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e78a8c",
   "metadata": {},
   "source": [
    "# 7장. 딥러닝을 위한 고급 도구(Advacned Tools for Deep Learning)\n",
    "※ 이 장에서 다룰 핵심 내용\n",
    "* 케라스의 함수형 API\n",
    "* 케라스 콜백 사용 방법\n",
    "* 시각화 도구인 텐서보드 사용 방법\n",
    "* 최고 수준의 모델을 만들기 위한 모범 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb8ce42",
   "metadata": {},
   "source": [
    "## 7.1 Sequential 모델을 넘어서: 케라스의 함수형 API\n",
    "* 지금까지 소개한 모든 신경망은 Sequential 모델을 사용하여 만들었습니다. Sequential 모델은 네트워크 입력과 출력이 하나라고 가정합니다. 이 모델은 층을 차례대로 쌓아 구성합니다.\n",
    "\n",
    "* 많은 경우에 이런 가정이 적절합니다. 이 책에서는 지금까지 Sequential 모델 클래스만 사용하여 많은 개념과 실제 application을 다루었습니다. 하지만 이런 가정이 맞지 않는 경우도 많습니다. 일부 네트워크는 개별 입력이 여러 개 필요하거나 출력이 여러 개 필요합니다. 층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크도 있습니다.\n",
    "\n",
    "* 예를 들어 어떤 작업은 다양한 종류의 입력이 필요합니다. 다양한 입력 소스(source)에서 전달된 데이터를 다른 종류의 신경망 층을 사용하여 처리하고 합칩니다. 중고 의류의 시장 가격을 예측하는 딥러닝 모델을 상상해 보죠. 이 모델은 사용자가 제공한 메타데이터(의류 브랜드, 연도 등), 사용자가 제공한 텍스트 설명, 제품 사진을 입력으로 사용합니다. 메타데이터만 있으면 이를 원-핫 인코딩으로 바꾸고 완전 연결 네트워크를 사용하여 가격을 예측할 수 있습니다. 텍스트 설명만 있다면 RNN이나 1D 컨브넷을 사용할 수 있습니다. 사진 이미지만 있다면 2D 컨브넷을 사용할 수 있습니다. 이 세 모델을 동시에 모두 사용할 수 있을까요? 간단한 방법은 3개의 모델을 따로 훈련하고 각 예측을 가중 평균(weighted average)하는 것입니다. 각 모델에서 추출한 정보가 중복된다면 이 방식은 최적이 아닐 것입니다. 가능한 모든 종류의 입력 데이터를 동시에 사용해서 정확한 하나의 모델을 학습하는 것이 더 나은 방법입니다. 이 모델은 3개의 입력 가지가 필요합니다.\n",
    "\n",
    "* 이와 비슷하게 어떤 작업은 입력 데이터에서 여러 개의 타깃 속성을 예측해야 합니다. 예를 들어 소설이나 짧은 글이 있을 때 자동으로 장르별로 분류하려고 합니다(로맨스나 스릴러 등). 또 글을 쓴 대략의 시대를 예측해야 합니다. 물론 2개의 모델을 따로 훈련할 수 있습니다. 장르를 위한 모델과 시대를 위한 모델입니다. 하지만 이 속성들은 통계적으로 독립적이지 않기 때문에 동시에 장르와 시대를 함께 예측하도록 학습해야 더 좋은 모델을 만들 수 있습니다. 이 모델은 2개의 출력 또는 머리(head)를 가집니다. 장르와 시대 사이의 상관관계 때문에 소설 시대를 알면 장르의 공간에서 정확하고 풍부한 표현을 학습하는 데 도움이 됩니다. 그 반대도 마찬가지입니다.\n",
    "\n",
    "* 더불어 최근에 개발된 많은 신경망 구조는 선형적이지 않은 네트워크 토폴로지(topology)가 필요합니다. 비순환 유향 그래프 같은 네트워크 구조입니다. 예를 들어 (구글의 세게대 등이 개발한)인셉션 모듈을 사용하는 인셉션 계열의 네트워크들입니다. 이 모듈에서 입력은 나란히 놓인 여러 개의 합성곱 층을 거쳐 하나의 텐서로 출력이 합쳐집니다.\n",
    "\n",
    "* 최근에는 모델에 **잔차 연결**을 추가하는 경향도 있습니다. (마이크로소프트의 허(He) 등이 개발한) ResNet 계열의 네트워크들이 이런 방식을 사용하기 시작했습니다. 잔차 연결은 하위 층의 출력 텐서를 상위 층의 출력 텐서에 더해서 아래층의 표현이 네트워크 위쪽으로 흘러갈 수 있도록 합니다. 하위 층에서 학습된 정보가 데이터 처리 과정에서 손실되는 것을 방지합니다. 이렇게 그래프 구조를 띤 네트워크 종류가 많습니다.\n",
    "★ 잔차 연결: 하위 층의 출력을 상위 층의 특성 맵에 더한다.\n",
    "* 여러 경우에 다중 입력 모델, 다중 출력 모델, 그래프 구조를 띤 모델이 필요하지만 케라스의 Sequential 클래스를 사용해서는 만들지 못합니다. 케라스에는 훨씬 더 일반적이고 유연한 다른 방법인 **함수형 API**가 있습니다. 이 절에서 함수형 API가 무엇인지 소개하고, 함수형 API를 사용하는 방법과 이를 사용하여 할 수 있는 것을 자세히 설명하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece66db7",
   "metadata": {},
   "source": [
    "### 7.1.1 함수형 API 소개\n",
    "* 함수형 API(functional API)에서는 직접 텐서들의 입출력을 다룹니다. 함수처럼 층을 사용하여 텐서를 입력받고 출력합니다(그래서 함수형 API라고 부릅니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bdc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "# 텐서(tensor)\n",
    "input_tensor = Input(shape=(32,))\n",
    "# 함수처럼 사용하기 위해 층 객체를 만듭니다.\n",
    "dense = layers. Dense(32, activation='relu')\n",
    "# 텐서와 함께 층을 호출하면 텐서를 반환합니다.\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e7f38",
   "metadata": {},
   "source": [
    "* 간단한 예를 통해 Sequential 모델과 함수형 API로 만든 동일한 모델을 나란히 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c79e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential 모델과 함수형 API로 만든 동일한 모델을 비교\n",
    "# Compare Sequential model with the same model which created by functional API\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 함수형 API로 만든 모델입니다.\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 입력과 출력 텐서를 지정하여 Model 클래스의 객체를 만듭니다.\n",
    "model = Model(input_tensor, output_tensor)\n",
    "# 모델 구조를 확인해 보죠!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5dfce",
   "metadata": {},
   "source": [
    "* 입력 텐서와 출력 텐서만 가지고 Model 객체를 만드는 부분이 조금 마술처럼 보입니다. 무대 뒤에서 케라스는 input_tensor에서 output_tensor로 가는 데 필요한 모든 층을 추출합니다. 그다음 이들을 모아 그래프 데이터 구조인 Model 객체를 만듭니다. 물론 input_tensor를 반복 변환하여 output_tensor를 만들 수 있어야 됩니다. 관련되지 않은 입력과 출력으로 모델을 만들면 RuntimeError가 발생합니다.\n",
    "\n",
    "```python\n",
    ">>> unrelated_input = Input(shape=(32,))\n",
    ">>> bad_model = model = Model(unrelated_input, output_tensor)\n",
    "RuntimeError: Graph disconnected: cannot\n",
    "obtain value for tensor\n",
    "Tensor(\"input_1:0\", shape=(?, 64), dtype=float32) at layer \"input_1\".\n",
    "```\n",
    "* 이 에러는 케라스가 출력 텐서에서 input_1 텐서로 다다를 수 없다는 뜻입니다.\n",
    "\n",
    "* Model 객체를 사용한 컴파일, 훈련, 평가 API는 Sequential 클래스와 같습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 객체를 사용한 컴파일, 훈련, 평가 API 구현\n",
    "# implement compile, training, evaluation API by using Model object \n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "# 훈련을 위해 랜덤한 넘파이 데이터를 생성합니다.\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 64))\n",
    "# 열 번 에포트 동안 모델을 훈련합니다.\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "# 모델을 평가합니다.\n",
    "score = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa2d47",
   "metadata": {},
   "source": [
    "### 7.1.2 다중 입력 모델(multi-input model)\n",
    "* 함수형 API는 다중 입력 모델을 만드는 데 사용할 수 있습니다. 일반적으로 이런 모델은 서로 다른 입력 가지를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용합니다. 텐서를 더하거나 이어 붙이는 식입니다. 이와 관련된 케라스의 함수는 keras, layers.add, keras.layers.concatenate 등입니다. 아주 간단한 다중 입력 모델을 살펴보겠습니다. 질문-응답(question-answering) 모델입니다.\n",
    "\n",
    "※ 이외에도 layers.average(), layers.maximum(), layers.minimum(), layers.multiply(), layers.subtract(), layers.dot()이 있습니다. 이 함수들은 tensorflow.keras.layers.merge 모듈 아래 정의되어 있습니다.\n",
    "\n",
    "* 전형적인 질문-응답 모델은 2개의 입력을 가집니다. 하나는 자연어 질문이고, 또 하나는 답변에 필요한 정보가 담겨 있는 텍스트(예를 들어 뉴스 기사)입니다. 그러면 모델은 답을 출력해야 합니다. 가장 간단한 구조는 미리 정의한 어휘 사전에서 소프트맥스 함수를 통해 한 단어로 된 답을 출력하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c4e5c",
   "metadata": {},
   "source": [
    "* 다음은 함수형 API를 사용하여 이런 모델을 만드는 예입니다. 텍스트와 질문을 벡터로 인코딩하여 독립된 입력 2개를 정의합니다. 그 다음 이 벡터를 연결하고 그 위에 소프트맥스 분류기를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964be6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 입력을 가진 질문-응답 모델의 함수형 API구현하기\n",
    "# implement functional API of question-answer model with two inputs\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# 텍스트 입력은 길이가 정해지지 않은 시퀀스입니다. 입력 이름을 지정할 수 있습니다.\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "embedded_text = layers.Embedding(\n",
    "    # 입력을 크기가 64인 벡터의 시퀀스로 임베딩합니다.\n",
    "    text_vocabulary_size, 64)(text_input)\n",
    "\n",
    "# LSTM을 사용하여 이 벡터들을 하나의 벡터로 인코딩합니다.\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,),\n",
    "                       dtype='int32',\n",
    "                       name='question') # 질문도 동일한 과정을 거칩니다(층 객체는 다릅니다).\n",
    "\n",
    "embedded_question = layers.Embedding(\n",
    "    question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# 인코딩된 질문과 텍스트를 연결합니다.\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question],\n",
    "                     axis=-1)\n",
    "\n",
    "# 소프트맥스 분류기를 추가합니다.\n",
    "answer = layers.Dense(answer_vocabulary_size,\n",
    "                            activation='softmax')(concatenated)\n",
    "# 모델 객체를 만들고 2개의 입력과 출력을 주입합니다.\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e2d72",
   "metadata": {},
   "source": [
    "* 그럼 이렇게 입력이 2개인 모델은 어떻게 훈련할까요? 두 가지 방식이 있습니다. 넘파이 배열의 리스트를 주입하거나 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 주입할 수 있습니다. 당연하게 두 번째 방식은 입력 이름을 설정했을 때 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a905f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 8s 168ms/step - loss: 6.2147 - acc: 0.0010\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 6.1931 - acc: 0.0360\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 6.1299 - acc: 0.0090\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 155ms/step - loss: 6.0547 - acc: 0.0070\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 181ms/step - loss: 6.0011 - acc: 0.0080\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 5.9217 - acc: 0.0060\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 5.8352 - acc: 0.0090\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 174ms/step - loss: 5.7370 - acc: 0.0200\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 151ms/step - loss: 5.6496 - acc: 0.0310\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 5.5731 - acc: 0.0360\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 5s 186ms/step - loss: 5.5016 - acc: 0.0390\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 5.4533 - acc: 0.0480\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 5.3722 - acc: 0.0460\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 5.3069 - acc: 0.0400\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 5.2478 - acc: 0.0380\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 5.1920 - acc: 0.0440\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 185ms/step - loss: 5.1297 - acc: 0.0450\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 5.0691 - acc: 0.0480\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 5.0111 - acc: 0.0730\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 4.9890 - acc: 0.0600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c3800df40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 입력 모델에 데이터 주입하기\n",
    "# Data injection in multi-input model\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 랜덤한 넘파이 데이터를 생성합니다.\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                             size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "\n",
    "# 답은 정수가 아닌 원-핫 인코딩된 벡터입니다.\n",
    "answers = to_categorical(answers)\n",
    "\n",
    "# 리스트 입력을 사용하여 학습합니다.\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# 딕셔너리 입력을 사용하여 학습합니다(입력 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "           epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2612cf",
   "metadata": {},
   "source": [
    "### 7.1.3 다중 출력 모델\n",
    "* 같은 식으로 함수형 API 모델을 사용하여 다중 출력(또는 다중 머리) 모델을 만들 수 있습니다. 간단한 예는 데이터에 있는 여러 속성을 동시에 예측하는 네트워크입니다. 예를 들어 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준 등을 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a67f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 출력을 가진 함수형 API 구현하기\n",
    "# implement functional API with having three outputs\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 출력 층에 이름을 지정합니다.\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "                                 activation='softmax',\n",
    "                                 name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input,\n",
    "              [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb056ca3",
   "metadata": {},
   "source": [
    "* 이런 모델을 훈련하려면 네트워크 출력마다 다른 손실 함수를 지정해야 합니다. 예를 들어 나이 예측은 스칼라 회귀 문제이지만 성별 예측은 이진 클래스 문제라 훈련 방식이 다릅니다. 경사 하강법은 하나의 스칼라 값을 최소화하기 때문에 모델을 훈련하려면 이 손실들을 하나의 값으로 합쳐야 합니다. 손실 값을 합치는 가장 간단한 방법은 모두 더하는 것입니다. 케라스에서는 compile 메서드에 리스트나 딕셔너리를 사용하여 출력마다 다른 손실을 지정할 수 있습니다. 계산된 손실 값은 전체 손실 하나로 더해지고 훈련 과정을 통해 최소화됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c5bd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 출력 모델의 컴파일 옵션: 다중 손실\n",
    "# compile option of multiple output models: multiple loss\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crosssentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4d044",
   "metadata": {},
   "source": [
    "* 손실 값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화할 것입니다. 그 결과 다른 작업들은 손해를 입습니다. 이를 해결하기 위해 손실 값이 최종 손실에 기여하는 수준을 지정할 수 있습니다. 특히 손실 값의 스케일이 다를 때 유용합니다. 예를 들어 다음과 같이 가정해 보죠. 나이 회귀 작업에 사용되는 평균 제곱 오차(MSE: Mean Square Error) 손실은 일반적으로 3~5 사이의 값을 가집니다. 반면에 성별 분류 작업에 사용되는 크로스엔트로피 손실은 0.1 정도로 낮습니다. 이런 환경에서 손실에 균형을 맞추려면 크로스엔트로피 손실에 가중치 10을 주고 MSE 손실에 가중치 0.25를 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dfe8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 출력 모델의 컴파일 옵션: 손실 가중치\n",
    "# compile option of multiple output models: loss weight\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crosssentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5af8d",
   "metadata": {},
   "source": [
    "* 다중 입력 모델과 마찬가지로 넘파이 배열의 리스트나 딕셔너리를 모델에 전달하여 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8fa36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 출력 모델에 데이터 주입하기\n",
    "# Inject data of multiple output models\n",
    "\n",
    "# age_targets, income_targets, gender_targets가 넘파이 배열이라고 가정합니다.\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1145a37",
   "metadata": {},
   "source": [
    "### 7.1.4 층으로 구성된 비순환 유향 그래프\n",
    "* 함수형 API를 사용하면 다중 입력이나 다중 출력 모델뿐만 아니라 내부 토폴로지가 복잡한 네트워크도 만들 수 있습니다. 케라스의 신경망은 층으로 구성된 어떤 **비순환 유향 그래프(directed acyclic graph)** 도 만들 수 있습니다. 비순환이라는 것이 중요합니다. 다시 말해 이 그래프는 원형을 띨 수 없습니다. 텐서 x가 자기 자신을 출력하는 층의 입력이 될 수 없습니다. 만들 수 있는 루프(즉 순환 연결)는 순환 층의 내부에 있는 것뿐입니다.\n",
    "* 그래프로 구현된 몇 개의 신경망 컴포넌트가 널리 사용됩니다. 가장 유명한 2개는 인셉션 모듈과 잔차 연결입니다. 케라스에서 이 2개의 컴포넌트를 어떻게 구현하는지 살펴보겠습니다. 함수형 API를 사용하여 층의 그래프를 만드는 방법을 이해하는 데 도움이 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인셉션 모듈(Inception module)\n",
    "from tensorflow.keras import layers\n",
    "# 모든 가지는 동일한 스트라이드(2)를 사용합니다.\n",
    "# 출력 크기를 동일하게 만들어 하나로 합치기 위해서입니다.\n",
    "branch_a = layers.Conv2D(128, 1,\n",
    "                         activation='relu', strides=2)(x)\n",
    "# 이 가지에서는 두 번째 합성곱 층에서 스트라이드를 적용합니다.\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "# 이 가지에서는 평균 폴링 층에서 스트라이드를 적용합니다.\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "# 모든 가지의 출력을 연결하여 모듈의 출력을 만듭니다.\n",
    "output = layers.concatenate(\n",
    "    [branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c3e02",
   "metadata": {},
   "source": [
    "#### 잔차 연결(residual connection)\n",
    "\n",
    "* 다음 코드는 케라스에서 특성 맵의 크기가 같을 때 원본을 그대로 사용하는 잔차 연결을 구현한 예입니다. 여기서는 입력 x가 4D 텐서라고 가정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 맵의 크기가 같을 때 잔차 연결 구현하기\n",
    "# implement residual connection when property maps are the same size\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "x = ...\n",
    "# x에 어떤 변환을 적용합니다.\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "# 원본 x를 출력 특성에 더합니다.\n",
    "y = layers.add([y, x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
